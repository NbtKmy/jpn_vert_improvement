<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					## Verbesserung des OCR-Verfahrens f√ºr Inhaltsverzeichnisse japanischsprachiger Materialien II
				</section>
				<section>
					<section  data-markdown>
						* Das Ziel des ganzen Projekts
						* Was ist bisher erreicht?
						* Das Modell "jpn_vert (best)" Verbessern
					</section>
				</section>
				<section>
					<section  data-markdown>
						# Das Ziel des Projekts
					</section>
					<section  data-markdown>
						## Inhaltsverzeichnisse im vertikalen japanischen Schrift automatisch erschliessen
					</section>
					<section  data-markdown>
						<img scr="https://nbtkmy.github.io/jpn_vert_improvement/presentation/bsp1_2.png" width="500px">
					</section>
					<section  data-markdown>
						<img scr="https://nbtkmy.github.io/jpn_vert_improvement/presentation/bsp_furigana.png" width="200px">
					</section>
					<section  data-markdown>
						<img scr="https://nbtkmy.github.io/jpn_vert_improvement/presentation/res_00.jpg" width="500px">
					</section>
				</section>
				<section>
					<section  data-markdown>
						# Was ist bisher erreicht?
					</section>
					<section  data-markdown>
						### Vorarbeitungsprozess automatisiert mit Python  
						* Zuerst Textbereich markieren...
						<img scr="https://nbtkmy.github.io/jpn_vert_improvement/presentation/res.jpg" width="500px">
					</section>
					<section  data-markdown>
						### Vorarbeitungsprozess automatisiert mit Python  
						* Danach den Aussenbereich mit der weissen Farben f√ºllen
						<img scr="https://nbtkmy.github.io/jpn_vert_improvement/presentation/result.png" width="500px">
					</section>
				</section>
				<section>
					<section  data-markdown>
						# Das Modell "jpn_vert (best)" Verbessern
					</section>
					<section  data-markdown>
						## Methode Fine tuning
					</section>
					<section  data-markdown>
						### Fine tuning?
						* Es wird ein OCR-Modell nicht von Anfang an erstellt
						* Sondern ein bereits existierendes Modell "jpn_vert (best)" wird durch weiteres Training verbessert
						* Das Modell ist https://github.com/tesseract-ocr/tessdata_best zu finden
					</section>
					<section  data-markdown>
						### Trainingsdaten f√ºr Fine tuning
						* Ground truth Daten aus Image und Texte
						* Ein Textkorpus zuerst erstellen
						* Der Textkorpus zeilenweise in die Bilder umwandeln
					</section>
					<section  data-markdown>
						### Textkorpus
						* Text aus Wikipedia
						* Werktitel aus Authorit√§tsdaten von National Diet Library (NDL)
					</section>
					<section  data-markdown>
						### Text aus Wikipedia
						* Die gesamten japanischsprachigen Wikipedia-Artikel als Dump
						* Hier: https://dumps.wikimedia.org/jawiki/latest/ (jawiki-latest-pages-articles.xml.bz2 am 01.05.2021)
						* Mit [Wikiextraktor](https://github.com/attardi/wikiextractor) von XML zu Text umwandeln
					</section>
					<section  data-markdown>
						### Wikipedia-Texte aus Dump extrahieren I 
						1. `pip install wikiextractor`  
						1. `python -m wikiextractor.WikiExtractor jawiki-latest-pages-articles.xml`
					</section>
					<section  data-markdown>
						### Wikipedia-Texte aus Dump extrahieren II
						1. `find text/ | grep wiki | awk '{system("cat "$0" >> wiki.txt")}'`  
						1. `sed -i '/^<[^>]*>$/d' wiki.txt`  
						1. `sed -i '/^$/d' wiki.txt`  
						1. `sed -e '/\.$/d' ./wiki.txt > ./wiki_v2.txt`  
						1. `sed -e 's/„ÄÇ/„ÄÇ\n/g' ./wiki_v2.txt | sed -e '/^$/d' > ./wiki_v3.txt`  
					</section>
					<section  data-markdown>
						### Werktitel aus Authorit√§tsdaten von der NDL
						1. [NDL Web Authorities](https://id.ndl.go.jp/auth/ndla) erlaubt [SPARQL-Query](https://id.ndl.go.jp/auth/ndla?query=PREFIX+skos%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2004%2F02%2Fskos%2Fcore%23%3E%0D%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0D%0APREFIX+rda%3A+%3Chttp%3A%2F%2FRDVocab.info%2FElementsGr2%2F%3E%0D%0APREFIX+foaf%3A+%3Chttp%3A%2F%2Fxmlns.com%2Ffoaf%2F0.1%2F%3E%0D%0APREFIX+xl%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2008%2F05%2Fskos-xl%23%3E%0D%0APREFIX+ndl%3A+%3Chttp%3A%2F%2Fndl.go.jp%2Fdcndl%2Fterms%2F%3E%0D%0ASELECT+*+WHERE+%7B%0D%0A%3Furi1+skos%3AinScheme+%3Chttp%3A%2F%2Fid.ndl.go.jp%2Fauth%23uniformTitles%3E+%3B+skos%3AexactMatch+%3Flink+%3B+skos%3ArelatedMatch+%3Flink2.%0D%0A%3Furi1+xl%3AprefLabel+%5B+xl%3AliteralForm+%3Ftitle%5D.+%0D%0A%3Furi1+xl%3AaltLabel+%5B+xl%3AliteralForm+%3Falttitle%5D.+%0D%0AFILTER+regex%28%3Flink2%2C+%27%5E.*KG.*%27%29%0D%0A%7D%0D%0A%0D%0A&output=json) 
						1. Python library "[SparqlWrapper](https://github.com/RDFLib/sparqlwrapper)" installieren
						1. Eine [Python-Code](https://github.com/NbtKmy/jpn_vert_improvement/blob/main/training_data/ndl_sparql.py) schreiben und laufen lassen
					</section>
				</section>
				<section>
					<section  data-markdown>
						## Fine tuning
						* 3 Verfahren, mit 3 unterschiedlichen Datensets
						* 1 Datensets hat 1000 Paare von Textzeile und Image
						* Fine tuning immer vom jpn_vert (best) Modell ausgehend
					</section>
					<section  data-markdown>
						## 3 Datensets
						1. Datenset - eine Zeile besteht aus reinem Text
						1. Datenset - eine Zeile besteht aus Text, dem Leader-Zeichen ("Ô∏ô") und die Zahlen in chines. Schrift
						1. Datenset - eine Zeile besteht aus Text, dem Leader-Zeichen und die Zahlen in chines. Schrift. Die Zahlen im Image ist verkleinert dargestellt 
					</section>
					<section  data-markdown>
						1. Datenset
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/89.png" width="50px">
					</section>
					<section  data-markdown>
						2. Datenset
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/13.png" width="50px">
					</section>
					<section  data-markdown>
						3. Datenset
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/57.png" width="50px">
					</section>
					<section  data-markdown>
						## Fine tuning mit [tesstrain](https://github.com/tesseract-ocr/tesstrain)  
						`$ nohup time -f "Run time = %E\n" make training MODEL_NAME=jpn_vert START_MODEL=jpn_vert PSM=5 >> train.log 2>&1 &`  
						PSM (page segmentation modes)=5 bedeutet "assume a single uniform block of vertically aligned text".
					</section>
				</section>
				<section>
					<section  data-markdown>
						## Ergebnisse und Ausblick
					</section>
					<section>
						OCR mit dem normalen jpn_vert (best) Modell
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/ocr_res0.png" width="500px">
					</section>
					<section>
						Ergebnis mit dem 1. Dataset
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/ocr_res1.png" width="500px">
					</section>
					<section>
						Ergebnis mit dem 2. Dataset
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/ocr_res2.png" width="500px">
					</section>
					<section>
						Ergebnis mit dem 3. Dataset
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/ocr_res3.png" width="500px">
					</section>
					<section>
						Erkannte Textbereiche waren immer gleich  
						<img src="https://nbtkmy.github.io/jpn_vert_improvement/presentation/res_1.jpg" width="500px">
					</section>
					<section  data-markdown>
						## ... NICHT WIRKLICH BESSER GEWORDEN üòë...
					</section>
					<section  data-markdown>
						## AUSBLICK ODER M√ñGLICHE MASSNAHMEN  
						* Fine tuning mit den unterschiedlich grossen Leader-Zeichen ("Ô∏ô")
						* Die Leader-Zeichen und die kleineren Schriften in der Vorarbeitung ausfiltern
						* Oder vielleicht eine Layout-Erkennung mit Tensorflow o.√§.
						* Andere OCR-Software wie [kraken](https://github.com/mittagessen/kraken) in Betracht ziehen
					</section>
					<section  data-markdown>
						## Code & Data im Github-Repo  
						https://nbtkmy.github.io/jpn_vert_improvement/
					</section>
					<section  data-markdown>
						# Vielen Dank!
					</section>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
